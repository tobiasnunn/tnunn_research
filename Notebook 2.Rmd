---
title: "ENS-2002 Scientific Notebook MK2 number 2"
author: "Tobias Nunn"
date: "2025-01-13"
output: 
  html_document:
    toc: true
    theme:
      bg: "#fdfffc"
      fg: "#212b32"
      primary: "#003973"
      secondary: "#FAB600"
      success: "#8cc04b"
    toc_depth: 1
---

```{=html}
<style>
    body .main-container {
        max-width: 1200px;
    }
</style>
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyr)
library(tidyverse)
library(gt)
library(knitr)
```

# EggNog-Mapper initial test analysis(2025-01-10 to 2025-01-14)

## Introduction

Aaron emailed me back with advice on a way to make eggNog-mapper/2.1.12 on hawk work. As i am revising for an exam i cant spend too long on this. p.s. i think i did pretty good on the exam

## Methods

From the 10th to the 12th i tried running a **[[test file]]** i made earlier in december 2024, i may not have written about it as i didnt get anywhere at that time. This process was also hindered by hawk being very encumbered in the new year meaning it takes a good half day for any results to appear. On the 11th i managed to get a successful result with the .xlsx file i need for the heatmaps for accession 3Dt1c. Today(the 12th) i set off 3 jobs each containing 3 accessions to hopefully get the results of the remaining 9. If there are no complications i will then be in a place where i can obtain the .fastas for the online comparison accessions and then run them through eggNog-mapper. It should be noted that i used the same list of parameters i found on the web version of hawk for this, **[[[[[[[[[[screenshot attached]]]]]]]]]]]].** I had some marginal success, the second set of three finished in over 3 hours, the other 2 sets are still going strong after 8, so ill let them time out over night and see what i have, maybe they will complete, i did give them 12 hours.I then discovered the command `dbmem` which could help to speed up the process. I tested with **[[this file]]** set to run over night from roughly 9 30 pm on the 12th to 3 30 am on the 13th, totalling 6 hours for 5 files, not great. I then experimented with taking out some of the arguments `--evalue 0.001 --score 60 --pident 40 --query_cover 20 --subject_cover 20`, that produced **[[this script]]**. Tomorrow(14th) i will have a look at recreating run 1 with `dbmem` switched on.

## Results
Run one had mixed results, 3 sets of 3 ran in parallel, set 1 completed in 3 and a half hours, good. set 2 took 8 and a half hours, bad, set 3 timed out, very bad. so dont have the outputs needed for 1Dt100h or 1Dt1h. Run 2 was more successful, with 5 solid looking outputs in 6 hours. Run 3 did not improve on that time despite the extra parameters being cut.

## Conclusion
It could have been overcrowding on hawk, however it appears that running multiple sets in parallel adversely affects the result, however, i have not tested this with `dbmem` on. The large problem is the volume of samples required, the desired output is 3 heatmaps comparing KO pathways:
- Comparing genera inside sphingomonadaceae
- Comparing genera inside Microbacteriaceae
- Comparing the genera containing just our samples



```{r setup for counts, echo=FALSE}
  datafile <- read.csv("02_middle-analysis_outputs/gtdbtk_stuff/20241224_de_novo_wf/gtdbtk.bac120.decorated.tree-taxonomy", sep = "\t", header = FALSE)
names(datafile) <- c("accession", "path")
datafile <- datafile %>% 
  separate_wider_delim(
    path, 
    delim = "; ", 
    names = c("domain", "phylum", "class", "order", "family", "genus", "species"), 
    too_few = "align_start",
    too_many = "merge")
local <- filter(datafile, grepl("flye", accession))
families <- filter(datafile, family %in% local$family)
countinfamily <- filter(families, !family == "f__" ) %>% count(family, genus)
countingenus <- filter(families, genus %in% local$genus) %>% count(genus) 

```


### All tables {.tabset .tabset-pills}

#### Family Sphingomonadaceae

```{r chart-f__sphingo, echo=FALSE, warning=FALSE}
filter(countinfamily, family == "f__Sphingomonadaceae") %>% gt(groupname_col = "family") %>% opt_row_striping() %>% opt_stylize(style = 5, color = "blue") %>%
  summary_rows(
    #columns = where(is.numeric),
    columns = n,
    fns = list(
      Total = ~sum(., na.rm = TRUE)))  %>%
  tab_header(
    title = "Table 10 - count of genera in the family Sphingomonadaceae",
    subtitle = md("accessions as found in the .tree file outputted by gtdbtk analysis done on 2024-12-24")
  ) %>%
  cols_label(genus = "Family and Genus",
             n = "Number of Accessions")

```

#### Family Microbacteriaceae

```{r chart-f__Micro, echo=FALSE, warning=FALSE}
filter(countinfamily, family == "f__Microbacteriaceae") %>% gt(groupname_col = "family") %>% opt_row_striping() %>% opt_stylize(style = 5, color = "blue") %>%
  summary_rows(
    #columns = where(is.numeric),
    columns = n,
    fns = list(
      Total = ~sum(., na.rm = TRUE))) %>%
  tab_header(
    title = "Table 11 - count of genera in the family Microbacteriaceae",
    subtitle = md("accessions as found in the .tree file outputted by gtdbtk analysis done on 2024-12-24")
  )  %>%
  cols_label(genus = "Family and Genus",
             n = "Number of Accessions")
```

#### Our Genera

```{r chart-ourgens, echo=FALSE, warning=FALSE}
countingenus %>% gt() %>% opt_row_striping() %>% opt_stylize(style = 5, color = "blue") %>%
  grand_summary_rows(
    #columns = where(is.numeric),
    columns = n,
    fns = list(
      Total = ~sum(., na.rm = TRUE))) %>%
  tab_header(
    title = "Table 12 - count of genera from accessions produced at Bangor",
    subtitle = md("accessions as found in the .tree file outputted by gtdbtk analysis done on 2024-12-24") 
  ) %>%
  cols_label(genus = "Genus",
             n = "Number of Accessions")
```

###  {.unnumbered}

::: {style="background-color:yellow;"}
ðŸ“Œ ?: TODO: [go and compare the content of runs 2 and 3]
[eggnog-mapper on hawk is slow, possibly too slow to scale to where we need it to be. alternatives: 
> what scale are we looking at - 1693 samples for the family comparison
> could limit to genera with more than 30 samples
> screenscrape-method
> enlist more manpower to do online(if we have to do on web)]
:::